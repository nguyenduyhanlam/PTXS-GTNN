{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Encoder_Decoder.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMPc7c5sppUOhxuoTZWgZcL"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fTAjC1G4OF1N","colab_type":"text"},"source":["**0) Lý thuyết và nguồn dữ liệu** <br>\n","Nguồn dữ liệu được lấy từ trang web: https://github.com/stefan-it/nmt-en-vi/tree/master/data\n","\n","Lý thuyết tham khảo ở các tài liệu:\n","\n","\n","1.   Cho, K., Van Merriënboer, B., Bahdanau, D., & Bengio, Y. (2014). On the properties of neural machine translation: Encoder-decoder approaches. arXiv preprint arXiv:1409.1259.\n","2.   Rico Sennrich, Barry Haddow (2016). Linguistic Input Features Improve Neural Machine Translation.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hxUYaEMU1AaI","colab_type":"text"},"source":["**1) Chuẩn bị thư viện và dữ liệu**"]},{"cell_type":"markdown","metadata":{"id":"4RZDPppFDjtP","colab_type":"text"},"source":["Đầu tiên ta sẽ chuẩn bị một số thư viện"]},{"cell_type":"code","metadata":{"id":"-WgSYmr_0x7R","colab_type":"code","outputId":"85d69d42-a74d-4912-faac-60a201c887c8","executionInfo":{"status":"ok","timestamp":1586537850272,"user_tz":-420,"elapsed":7362,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","!pip install unidecode\n","import unidecode\n","import string\n","import re\n","import random\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\r\u001b[K     |█▍                              | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 4.5MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.1.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IJUJlhLxDqPC","colab_type":"text"},"source":["Chuẩn bị dữ liệu cho chương trình"]},{"cell_type":"code","metadata":{"id":"mUbTp8MXD-qB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"d6b45ed9-be64-45a4-aa76-19e30d033c37","executionInfo":{"status":"ok","timestamp":1586540547267,"user_tz":-420,"elapsed":6759,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}}},"source":["!git clone https://github.com/nguyenduyhanlam/PTXS-GTNN\n","!ls"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Cloning into 'PTXS-GTNN'...\n","remote: Enumerating objects: 15, done.\u001b[K\n","remote: Counting objects: 100% (15/15), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 15 (delta 0), reused 15 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (15/15), done.\n","adc.json  Filename.csv\tPTXS-GTNN  sample_data\ttst2013.en  tst2013.vn\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jyy93Abf3D6C","colab_type":"text"},"source":["**2) Load dữ liệu** <br>\n","Ta sẽ tạo class ngôn ngữ dùng để load dữ liệu từ file text. <br>\n","Class ngôn ngữ gồm có các **thuộc tính** cơ bản sau:\n","*   **name**: tên của ngôn ngữ (English, tiếng Việt,...)\n","*   **word2index**: bộ từ điển.\n","*   **word2count**: bộ đếm từ.\n","*   **index2word**: bộ lưu vị trí các token.\n","*   **n_words**: đếm tổng các lượng từ.\n","\n","Class ngôn ngữ gồm có các **hàm** cơ bản sau:\n","*   **addSentence**: Có tham số là sentence, dùng để truyền vào 1 câu văn bản. Từ câu văn bản này, ta sẽ tách thành các từ (word). Cuối cùng ta sẽ lưu các từ này vào bộ từ điển bằng hàm addWord.\n","*   **addWord**: Có tham số là word, dùng để truyền vào 1 từ (word), nếu từ này chưa có trong bộ từ điển thì sẽ được thêm (add) mới vào bộ từ điển. Nếu đã có rồi ta sẽ tăng số lần xuất hiện (số đếm) của từ này thêm 1 đơn vị.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"pM_AUaFqH_zO","colab_type":"code","colab":{}},"source":["SOS_token = 0 #Start Of Sequence\n","EOS_token = 1 #End Of Sequence\n","PAD_token = 2 # Used for padding short sentences\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hOqMx1fwDtaW","colab_type":"text"},"source":["Ta cần triển khai thêm một số hàm bổ trợ như:\n","*   **remove_accent**: dùng để loại bỏ các dấu thanh (sắc, hỏi, huyền, ngã, nặng,...).\n","*   **normalizeString**: Dùng để chuẩn hóa câu để chạy chương trình. Đầu tiên ta sẽ loại bỏ hết các dấu thanh ra khỏi câu. Sau đó ta sẽ tách các dấu câu (dấu phẩy, dấu chấm, dấu chấm hỏi, dấu chấm thang,...) ra khỏi từ.\n","\n","Ví dụ ta có câu: \"Ăn quả, nhớ kẻ trồng cây.\". Sau khi chạy hàm **normalizeString** ta sẽ được kết quả là: \"An qua , nho ke trong cay .\"\n","\n"]},{"cell_type":"code","metadata":{"id":"Qj-oU1nND-F1","colab_type":"code","outputId":"37fc97cb-bc70-4710-dd44-57b9f2f280c2","executionInfo":{"status":"ok","timestamp":1586539619981,"user_tz":-420,"elapsed":868,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# remove all the accents\n","def remove_accent(utf8_str):\n","    return unidecode.unidecode(utf8_str)\n","\n","# Normalize the string (marks and words are seperated, words don't contain accents,...)\n","def normalizeString(s):\n","    # Remove all the accents first.\n","    s = remove_accent(s)\n","    # Seperate words and marks by adding spaces between them\n","    marks = '[.!?,-${}()]'\n","    r = \"([\"+\"\\\\\".join(marks)+\"])\"\n","    s = re.sub(r, r\" \\1 \", s)\n","    # replace continuous spaces with a single space\n","    s = re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","\n","# Example\n","ex_s = \"Ăn quả, nhớ kẻ trồng cây.\"\n","print(normalizeString(ex_s)) # result will be \"An qua , nho ke trong cay .\""],"execution_count":11,"outputs":[{"output_type":"stream","text":["An qua , nho ke trong cay .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5ptWmB5UTttq","colab_type":"text"},"source":["Cuối cùng ta sẽ thực hiện việc load dữ liệu."]},{"cell_type":"code","metadata":{"id":"jpgXPOsdT2vi","colab_type":"code","outputId":"5b1db6ae-9136-46fc-b673-23a5657976ce","executionInfo":{"status":"ok","timestamp":1586541220855,"user_tz":-420,"elapsed":828,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["def readLangs(lang1, lang2):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines_language1 = open('tst2013.%s' % lang1, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","    lines_language2 = open('tst2013.%s' % lang2, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Normalize all the lines\n","    data_language1 = [normalizeString(l) for l in lines_language1]\n","    data_language2 = [normalizeString(l) for l in lines_language2]\n","\n","    # Prepare return values\n","    input_lang = Lang(lang1)\n","    output_lang = Lang(lang2)\n","    data = list(zip(data_language1, data_language2))\n","\n","    return input_lang, output_lang, data\n","\n","# Test the function\n","lang1 = \"en\"\n","lang2 = \"vn\"\n","input_lang, output_lang, data = readLangs(lang1, lang2)\n","print(\"Language 1:\", input_lang.name)\n","print(\"Language 2:\", output_lang.name)\n","print(random.choice(data))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Reading lines...\n","Language 1: en\n","Language 2: vn\n","('Guess what ?', 'Nghi thu xem nhe ?')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VPlUxPSnheDR","colab_type":"text"},"source":["Chương trình sẽ chạy nhanh hơn khi chúng ta cắt bộ dữ liệu thành các câu ngắn và đơn giản. Ở đây ta sẽ giới hạn cho 1 câu có tối đa là 10 từ (bao gồm cả dấu chấm câu).\n"]},{"cell_type":"markdown","metadata":{"id":"pc_5i5o3hjUK","colab_type":"text"},"source":["**3) Chuẩn bị dữ liệu** <br>\n"]},{"cell_type":"code","metadata":{"id":"LOuJkWgQhtN4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}