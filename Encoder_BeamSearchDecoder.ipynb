{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Encoder_BeamSearchDecoder.ipynb","provenance":[],"authorship_tag":"ABX9TyN3cC3XkA/YQT2W2g/M4+O8"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QsbTy5uTFId2","colab_type":"text"},"source":["**0) Lý thuyết và nguồn dữ liệu** <br>\n","Nguồn dữ liệu được lấy từ trang web: https://github.com/stefan-it/nmt-en-vi/tree/master/data\n","\n","Lý thuyết tham khảo ở các tài liệu:\n","\n","\n","1.   Cho, K., Van Merriënboer, B., Bahdanau, D., & Bengio, Y. (2014). On the properties of neural machine translation: Encoder-decoder approaches. arXiv preprint arXiv:1409.1259.\n","2.   Rico Sennrich, Barry Haddow (2016). Linguistic Input Features Improve Neural Machine Translation.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Q_okhvS7FNHZ","colab_type":"text"},"source":["**1) Chuẩn bị thư viện và dữ liệu**\n","\n","Đầu tiên ta sẽ chuẩn bị một số thư viện"]},{"cell_type":"code","metadata":{"id":"5L3JdpgCE8VV","colab_type":"code","colab":{}},"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import unidecode\n","import string\n","import re\n","import random\n","import numpy as np\n","import html\n","from queue import PriorityQueue\n","import operator\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JJ3phUWpFW0S","colab_type":"text"},"source":["Chuẩn bị dữ liệu cho chương trình"]},{"cell_type":"code","metadata":{"id":"hW4sEi6GFYxO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"e4e4896e-ce9e-460c-f8af-94407fee855b","executionInfo":{"status":"ok","timestamp":1588990073897,"user_tz":-420,"elapsed":7442,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}}},"source":["!git clone https://github.com/nguyenduyhanlam/PTXS-GTNN\n","!ls\n","import os\n","os.getcwd()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'PTXS-GTNN'...\n","remote: Enumerating objects: 60, done.\u001b[K\n","remote: Counting objects: 100% (60/60), done.\u001b[K\n","remote: Compressing objects: 100% (48/48), done.\u001b[K\n","remote: Total 60 (delta 31), reused 41 (delta 12), pack-reused 0\u001b[K\n","Unpacking objects: 100% (60/60), done.\n","PTXS-GTNN  sample_data\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"l7t7AZEdFbQ0","colab_type":"text"},"source":["Ta cần chuẩn bị thêm thư viện phục vụ cho việc lemmas hóa."]},{"cell_type":"code","metadata":{"id":"VXBuOaOQFcKA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"9da02d85-544a-4790-b63a-992b1f75bad7","executionInfo":{"status":"ok","timestamp":1588990077988,"user_tz":-420,"elapsed":2891,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}}},"source":["import nltk\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","wordnet_lemmatizer = WordNetLemmatizer()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BYG6Bws3FeyQ","colab_type":"text"},"source":["**2) Load dữ liệu** <br>\n","Ta sẽ tạo class ngôn ngữ dùng để load dữ liệu từ file text. <br>\n","Class ngôn ngữ gồm có các **thuộc tính** cơ bản sau:\n","*   **name**: tên của ngôn ngữ (English, tiếng Việt,...)\n","*   **word2index**: bộ từ điển.\n","*   **word2count**: bộ đếm từ.\n","*   **index2word**: bộ lưu vị trí các token.\n","*   **n_words**: đếm tổng các lượng từ.\n","\n","Class ngôn ngữ gồm có các **hàm** cơ bản sau:\n","*   **addSentence**: Có tham số là sentence, dùng để truyền vào 1 câu văn bản. Từ câu văn bản này, ta sẽ tách thành các từ (word). Cuối cùng ta sẽ lưu các từ này vào bộ từ điển bằng hàm addWord.\n","*   **addWord**: Có tham số là word, dùng để truyền vào 1 từ (word), nếu từ này chưa có trong bộ từ điển thì sẽ được thêm (add) mới vào bộ từ điển. Nếu đã có rồi ta sẽ tăng số lần xuất hiện (số đếm) của từ này thêm 1 đơn vị."]},{"cell_type":"code","metadata":{"id":"NCpshSs0Ff5D","colab_type":"code","colab":{}},"source":["SOS_token = 0 #Start Of Sequence\n","EOS_token = 1 #End Of Sequence\n","PAD_token = 2 # Used for padding short sentences\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FkOnzgGeFif-","colab_type":"text"},"source":["Ta cần triển khai thêm một số hàm bổ trợ như:\n","*   **remove_accent**: dùng để loại bỏ các dấu thanh (sắc, hỏi, huyền, ngã, nặng,...).\n","*   **normalizeString**: Dùng để chuẩn hóa câu để chạy chương trình. Đầu tiên ta sẽ loại bỏ hết các dấu thanh ra khỏi câu. Sau đó ta sẽ tách các dấu câu (dấu phẩy, dấu chấm, dấu chấm hỏi, dấu chấm thang,...) ra khỏi từ. Ngoài ra ta sẽ chuyển bớt một số dạng thể ngắn của tiếng anh về dạng thường.\n","\n","Ví dụ ta có câu: \"Ăn quả, nhớ kẻ trồng cây.\". Sau khi chạy hàm **normalizeString** ta sẽ được kết quả là: \"An qua , nho ke trong cay .\""]},{"cell_type":"code","metadata":{"id":"gR79KNk-FlYB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"eb60fa63-3390-48be-cd29-4786b3771c9d","executionInfo":{"status":"ok","timestamp":1588990086492,"user_tz":-420,"elapsed":800,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}}},"source":["# remove all the accents\n","def remove_accent(utf8_str):\n","    return unidecode.unidecode(utf8_str)\n","\n","contractions = {\n","\"ain 't\": \"am not / are not\",\n","\"aren 't\": \"are not / am not\",\n","\"can 't\": \"cannot\",\n","\"can 't 've\": \"cannot have\",\n","\"'cause\": \"because\",\n","\"could 've\": \"could have\",\n","\"couldn 't\": \"could not\",\n","\"couldn 't 've\": \"could not have\",\n","\"didn 't\": \"did not\",\n","\"doesn 't\": \"does not\",\n","\"don 't\": \"do not\",\n","\"hadn 't\": \"had not\",\n","\"hadn 't 've\": \"had not have\",\n","\"hasn 't\": \"has not\",\n","\"haven 't\": \"have not\",\n","\"he 'd\": \"he had / he would\",\n","\"he 'd 've\": \"he would have\",\n","\"he 'll\": \"he shall / he will\",\n","\"he 'll 've\": \"he shall have / he will have\",\n","\"he 's\": \"he has / he is\",\n","\"how'd\": \"how did\",\n","\"how'd 'y\": \"how do you\",\n","\"how 'll\": \"how will\",\n","\"how 's\": \"how has / how is\",\n","\"i 'd\": \"I had / I would\",\n","\"i 'd 've\": \"I would have\",\n","\"i 'll\": \"I shall / I will\",\n","\"i 'll 've\": \"I shall have / I will have\",\n","\"i 'm\": \"I am\",\n","\"i 've\": \"I have\",\n","\"isn 't\": \"is not\",\n","\"it 'd\": \"it had / it would\",\n","\"it 'd've\": \"it would have\",\n","\"it 'll\": \"it shall / it will\",\n","\"it 'll've\": \"it shall have / it will have\",\n","\"it 's\": \"it has / it is\",\n","\"let 's\": \"let us\",\n","\"ma 'am\": \"madam\",\n","\"mayn 't\": \"may not\",\n","\"might 've\": \"might have\",\n","\"mightn 't\": \"might not\",\n","\"mightn 't 've\": \"might not have\",\n","\"must 've\": \"must have\",\n","\"mustn 't\": \"must not\",\n","\"mustn 't 've\": \"must not have\",\n","\"needn 't\": \"need not\",\n","\"needn 't 've\": \"need not have\",\n","\"o 'clock\": \"of the clock\",\n","\"oughtn 't\": \"ought not\",\n","\"oughtn 't 've\": \"ought not have\",\n","\"shan 't\": \"shall not\",\n","\"sha 'n 't\": \"shall not\",\n","\"shan 't 've\": \"shall not have\",\n","\"she 'd\": \"she had / she would\",\n","\"she 'd've\": \"she would have\",\n","\"she 'll\": \"she shall / she will\",\n","\"she 'll've\": \"she shall have / she will have\",\n","\"she 's\": \"she has / she is\",\n","\"should 've\": \"should have\",\n","\"shouldn 't\": \"should not\",\n","\"shouldn 't 've\": \"should not have\",\n","\"so 've\": \"so have\",\n","\"so 's\": \"so as / so is\",\n","\"that 'd\": \"that would / that had\",\n","\"that 'd 've\": \"that would have\",\n","\"that 's\": \"that has / that is\",\n","\"there 'd\": \"there had / there would\",\n","\"there 'd 've\": \"there would have\",\n","\"there 's\": \"there has / there is\",\n","\"they 'd\": \"they had / they would\",\n","\"they 'd 've\": \"they would have\",\n","\"they 'll\": \"they shall / they will\",\n","\"they 'll 've\": \"they shall have / they will have\",\n","\"they 're\": \"they are\",\n","\"they 've\": \"they have\",\n","\"to 've\": \"to have\",\n","\"wasn 't\": \"was not\",\n","\"we 'd\": \"we had / we would\",\n","\"we 'd 've\": \"we would have\",\n","\"we 'll\": \"we will\",\n","\"we 'll 've\": \"we will have\",\n","\"we 're\": \"we are\",\n","\"we 've\": \"we have\",\n","\"weren 't\": \"were not\",\n","\"what 'll\": \"what shall / what will\",\n","\"what 'll 've\": \"what shall have / what will have\",\n","\"what 're\": \"what are\",\n","\"what 's\": \"what has / what is\",\n","\"what 've\": \"what have\",\n","\"when 's\": \"when has / when is\",\n","\"when 've\": \"when have\",\n","\"where 'd\": \"where did\",\n","\"where 's\": \"where has / where is\",\n","\"where 've\": \"where have\",\n","\"who 'll\": \"who shall / who will\",\n","\"who 'll 've\": \"who shall have / who will have\",\n","\"who 's\": \"who has / who is\",\n","\"who 've\": \"who have\",\n","\"why 's\": \"why has / why is\",\n","\"why 've\": \"why have\",\n","\"will 've\": \"will have\",\n","\"won 't\": \"will not\",\n","\"won 't 've\": \"will not have\",\n","\"would 've\": \"would have\",\n","\"wouldn 't\": \"would not\",\n","\"wouldn 't 've\": \"would not have\",\n","\"y 'all\": \"you all\",\n","\"y 'all 'd\": \"you all would\",\n","\"y 'all 'd 've\": \"you all would have\",\n","\"y 'all 're\": \"you all are\",\n","\"y 'all 've\": \"you all have\",\n","\"you 'd\": \"you had / you would\",\n","\"you 'd 've\": \"you would have\",\n","\"you 'll\": \"you shall / you will\",\n","\"you 'll 've\": \"you shall have / you will have\",\n","\"you 're\": \"you are\",\n","\"you 've\": \"you have\"\n","}\n","\n","# Normalize the string (marks and words are seperated, words don't contain accents,...)\n","def normalizeString(s):\n","    # Remove all the accents first.\n","    s = remove_accent(html.unescape(s))\n","    # Seperate words and marks by adding spaces between them\n","    marks = '[.!?,-${}()]'\n","    r = \"([\"+\"\\\\\".join(marks)+\"])\"\n","    s = re.sub(r, r\" \\1 \", s)\n","    # replace continuous spaces with a single space\n","    s = re.sub(r\"\\s+\", r\" \", s).strip()\n","    \n","    # Convert to writing form\n","    for c in contractions:\n","        if c in s:\n","            s = s.replace(c, contractions[c].lower())\n","\n","    return s\n","\n","# Example\n","ex_s = \"Ăn quả, nhớ kẻ trồng cây.\"\n","print(normalizeString(ex_s)) # result will be \"An qua , nho ke trong cay .\""],"execution_count":6,"outputs":[{"output_type":"stream","text":["An qua , nho ke trong cay .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8CjfFg_jFob_","colab_type":"text"},"source":["Cuối cùng ta sẽ thực hiện việc load dữ liệu."]},{"cell_type":"code","metadata":{"id":"ZhLeFWEYFp_C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"622bb579-e1f8-4a9e-f0d6-8046a8542691","executionInfo":{"status":"ok","timestamp":1588990111927,"user_tz":-420,"elapsed":15266,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}}},"source":["def readLangs(lang1, lang2):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines_language1 = open('PTXS-GTNN/train.%s' % lang1, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","    lines_language2 = open('PTXS-GTNN/train.%s' % lang2, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Normalize all the lines\n","    data_language1 = [normalizeString(l.lower().strip()) for l in lines_language1]\n","    data_language2 = [normalizeString(l.lower().strip()) for l in lines_language2]\n","\n","    # Prepare return values\n","    input_lang = Lang(lang1)\n","    output_lang = Lang(lang2)\n","    data = list(zip(data_language1, data_language2))\n","\n","    return input_lang, output_lang, data\n","\n","# Test the function\n","lang1 = \"en\"\n","lang2 = \"vi\"\n","input_lang, output_lang, data = readLangs(lang1, lang2)\n","print(\"Language 1:\", input_lang.name)\n","print(\"Language 2:\", output_lang.name)\n","print(random.choice(data))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Reading lines...\n","Language 1: en\n","Language 2: vi\n","('it has / it is called the beijing genomics institute .', 'no duoc goi la vien gen bac kinh ,')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TqO4DqaxFsSl","colab_type":"text"},"source":["**3) Chuẩn bị dữ liệu**\n","\n","Chương trình sẽ chạy nhanh hơn khi chúng ta lọc bộ dữ liệu thành các câu ngắn và đơn giản. Ở đây ta sẽ giới hạn cho 1 câu có tối đa là 10 từ (bao gồm cả dấu chấm câu). Đồng thời ta viết hàm thực hiện lemmatization."]},{"cell_type":"code","metadata":{"id":"qwUnLy0dFzBy","colab_type":"code","colab":{}},"source":["MAX_LENGTH = 10\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]\n","\n","def lemmatizer(sentence):\n","    for word in sentence.split():\n","        sentence = sentence.replace(word, wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n","    return sentence"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jPvqoGSoF00B","colab_type":"text"},"source":["Sau quá trình biến đổi chúng ta sẽ có được tập dữ liệu để chuẩn bị cho huấn luyện."]},{"cell_type":"code","metadata":{"id":"S6aH8zu0F2iS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"e458b1e0-3b08-4983-e8ba-baa2a84d6a00","executionInfo":{"status":"ok","timestamp":1588990167678,"user_tz":-420,"elapsed":17541,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}}},"source":["def prepareData(lang1, lang2):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        # Lemmatization process\n","        inWord = lemmatizer(pair[0])\n","        outWord = lemmatizer(pair[1])\n","        # Add word to dictionaries after lemmatization\n","        input_lang.addSentence(inWord)\n","        output_lang.addSentence(outWord)\n","    print(\"Counted words:\")\n","    print(\"Language 1:\", input_lang.name, \"There are\", input_lang.n_words, \"different words\")\n","    print(\"Language 2:\", output_lang.name, \"There are\", output_lang.n_words, \"different words\")\n","    return input_lang, output_lang, pairs\n","\n","\n","input_lang, output_lang, pairs = prepareData('en', 'vi')\n","print(random.choice(pairs))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Reading lines...\n","Read 133317 sentence pairs\n","Trimmed to 14655 sentence pairs\n","Counting words...\n","Counted words:\n","Language 1: en There are 7111 different words\n","Language 2: vi There are 3114 different words\n","('seven different salts .', '7 loai muoi khac nhau')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kll4Z62aGCCk","colab_type":"text"},"source":["**4) Mô hình Encoder-Decoder**\n","\n","Đầu tiên ta sẽ đi xây dưng bộ encoder trước.\n","\n","---\n","\n","===================================**Encoder**===================================\n","\n","Mô hình encoder như sau:\n","\n","![Encoder example](https://drive.google.com/uc?id=1cyor63sz5r_-hnwXvptVDl_4-3ltsKzC)\n","\n","(Source: https://medium.com/@t.schnake/a-formalization-of-a-simple-sequential-encoder-decoder-b31be7e92988)\n","\n","![Pytorch encoder flow](https://drive.google.com/uc?id=1R5dtbS_Xl4wYZMJcL4BT47VEGX-lMMXR)\n","\n","(Source: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n","\n","Ta sẽ đi xây dựng một class có tên là EncoderRNN cho bộ GRU-RNN encoder.\n","\n","Class này có các thuộc tính cơ bản sau:\n","*   **hidden_size**: kích thước (số chiều) của vector của mỗi phần tử trong bộ từ điển.\n","*   **embedding**: lưu trữ kết quả của bộ từ điển sau khi thực hiện word embedding (tham khảo thêm về word embedding tại https://machinelearningmastery.com/what-are-word-embeddings/).\n","*   **gru**: cấu trúc GRU sẽ sử dụng.\n","\n","Trong hàm khởi tạo ta sẽ truyền vào các biến sau:\n","*   **input_size**: kích thước của bộ từ điển (số lượng từ có trong bộ từ điển).\n","*   **hidden_size**: kích thước (số chiều) của vector của mỗi phần tử trong bộ từ điển.\n"]},{"cell_type":"code","metadata":{"id":"HKH8Uqp0GFwd","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        \n","        # A simple lookup table that stores embeddings of a fixed dictionary \n","        # and size. \n","        # This module is often used to store word embeddings and retrieve them using indices. \n","        # The input to the module is a list of indices, \n","        # and the output is the corresponding word embeddings.\n","        # input_size: num_embeddings (python:int) – size of the dictionary of embeddings\n","        # hidden_size: embedding_dim (python:int) – the size of each embedding vector\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        \n","        # Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n","        # hidden_size: input_size – The number of expected features in the input x\n","        # hidden_size: hidden_size – The number of features in the hidden state h\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        # Create word embedding table based on the data -> tensor table\n","        # view(*shape): Returns a new tensor with the same data as the self tensor but of a different shape.\n","        embedded = self.embedding(input).view(1, 1, -1)\n","\n","        output = embedded\n","\n","        # Execute GRU process\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        # Initiate the first hidden unit\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ARJnUzBdGSeB","colab_type":"text"},"source":["===================================**Decoder**===================================\n","\n","Mô hình decoder cơ bản có thể được minh họa như sau:\n","\n","![Decoder example](https://drive.google.com/uc?id=15k-FuqT8oCaP3MkHV7W-5OQg072OzQsz)\n","\n","(Source: https://medium.com/@t.schnake/a-formalization-of-a-simple-sequential-encoder-decoder-b31be7e92988)\n","\n","![Pytorch base decoder flow](https://drive.google.com/uc?id=16Mt0xS53HsAczMiwZYbcBRC0x95wA_og)\n","\n","(Source: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n","\n","Class này có các thuộc tính cơ bản sau:\n","*   **hidden_size**: kích thước (số chiều) của vector của mỗi phần tử trong tập kết quả của encoder.\n","*   **embedding**: lưu trữ kết quả của bộ vector kết quả từ encoder sau khi thực hiện word embedding (tham khảo thêm về word embedding tại https://machinelearningmastery.com/what-are-word-embeddings/).\n","*   **gru**: cấu trúc GRU sẽ sử dụng.\n","*   **out**: đối tượng linear transformation.\n","*   **softmax**: đối tượng softmax.\n","\n","Trong hàm khởi tạo ta sẽ truyền vào các biến sau:\n","*   **hidden_size**: kích thước (số chiều) của vector của mỗi phần tử trong tập kết quả của encoder.\n","*   **output_size**: kích thước của kết quả đầu ra."]},{"cell_type":"code","metadata":{"id":"GXuJ_-J2GUtw","colab_type":"code","colab":{}},"source":["class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        # A simple lookup table that stores embeddings of a fixed dictionary \n","        # and size. \n","        # This module is often used to store word embeddings and retrieve them using indices. \n","        # The input to the module is a list of indices, \n","        # and the output is the corresponding word embeddings.\n","        # output_size: num_embeddings (python:int) – size of the dictionary of embeddings\n","        # hidden_size: embedding_dim (python:int) – the size of each embedding vector\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","\n","        # Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n","        # hidden_size: input_size – The number of expected features in the input x\n","        # hidden_size: hidden_size – The number of features in the hidden state h\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","        # Applies a linear transformation to the incoming data: y = xA^T + b\n","        # hidden_size: in_features – size of each input sample\n","        # output_size: out_features – size of each output sample\n","        self.out = nn.Linear(hidden_size, output_size)\n","        \n","        # Applies the log(Softmax(x) function to an n-dimensional input Tensor. The LogSoftmax formulation can be simplified as:\n","        # logSoftmax(xi) = log(exp(xi) / sum_j(exp(xj)))\n","        # dim=1: Input: (*) where * means, any number of additional dimensions\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        # Create word embedding table based on the data -> tensor table\n","        # view(*shape): Returns a new tensor with the same data as the self tensor but of a different shape.\n","        output = self.embedding(input).view(1, 1, -1)\n","        \n","        # Assuring the encoder output is not negative\n","        # Because ReLU output range is (0, +inf)\n","        output = F.relu(output)\n","\n","        # Execute GRU process\n","        output, hidden = self.gru(output, hidden)\n","\n","        # Calculate the softmax\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","    def initHidden(self):\n","        # Initiate the first hidden unit\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kq5eLU5NGXkJ","colab_type":"text"},"source":["**Decoder sử dụng attention**\n","\n","Attention là một cơ chế kỹ thuật nhằm giúp giải quyết các giới hạn của kiến trúc encoder-decoder trên các chuỗi dài (chuỗi dữ liệu đầu vào). Attention sẽ giúp tăng tốc độ học tập và cải thiện khả năng dự đoán của mô hình.\n","\n","Do vector ngữ cảnh này có độ dài cố định và là kết quả sau quá trình mã hóa từ dữ liệu đầu vào có độ dài thay đổi, nên vector này sẽ chứa rất nhiều thông tin. Việc mã hóa (decode) vector này sẽ là một áp lực lớn đối với decoder.\n","\n","Cơ chế attention cho phép tại mỗi bước input của decoder, decoder có thể tập trung vào từng phần khác nhau của encoder output. Đầu tiên, chúng ta sẽ tính tập trọng số attention (attention weight). Sau đó ta sẽ lấy tập trọng số này nhân với các vectơ đầu ra của encoder để tạo ra một tổ hợp có trọng số. Kết quả (được gọi là attn_applied) này giúp nhận biết được từng phần của chuỗi đầu vào, và từ đó sẽ giúp decoder chọn được từ (word) đầu ra đúng.\n","\n","Thay vì mã hóa chuỗi đầu vào thành một vectơ ngữ cảnh cố định duy nhất, mô hình chú ý phát triển một vectơ bối cảnh được lọc riêng cho từng bước thời gian t ở đầu ra.\n","\n","![Attention](https://drive.google.com/uc?id=1uK8t6wEnWEfpC4osuankfgH7WMXrx4ec)\n","\n","(Source: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n"]},{"cell_type":"code","metadata":{"id":"KUuAlLvLGbqw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":475},"outputId":"b9340d3c-4f32-4f41-8d0f-90ec7b35b979","executionInfo":{"status":"ok","timestamp":1588988602301,"user_tz":-420,"elapsed":885,"user":{"displayName":"Nguyễn Duy Hàn Lâm","photoUrl":"","userId":"15262702392422763405"}}},"source":["print(\"Source: https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3\")\n","from IPython.display import Image\n","Image(url='https://miro.medium.com/max/576/1*wBHsGZ-BdmTKS7b-BtkqFQ.gif')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Source: https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<img src=\"https://miro.medium.com/max/576/1*wBHsGZ-BdmTKS7b-BtkqFQ.gif\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"GmGeMUCFGfZf","colab_type":"text"},"source":["Ta sẽ đi xây dựng class decoder có sử dụng attention.\n","\n","![alt text](https://drive.google.com/uc?id=1MZ4vaGKFX5Q8cd-Z40i-rYRHg2yh5pDd)\n","\n","(Source: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n","\n","Class này có các thuộc tính cơ bản sau:\n","*   **hidden_size**: kích thước (số chiều) của vector của mỗi phần tử trong tập kết quả của encoder.\n","*   **output_size**: kích thước của đầu ra.\n","*   **dropout_p**: xác suất loại bỏ.\n","*   **max_length**: số lượng từ giới hạn cho 1 câu dịch.\n","*   **embedding**: lưu trữ kết quả của bộ vector kết quả từ encoder sau khi thực hiện word embedding (tham khảo thêm về word embedding tại https://machinelearningmastery.com/what-are-word-embeddings/).\n","*   **attn**: đối tượng attention khởi tạo.\n","*   **attn_combine**: đối tượng kết hợp attention.\n","*   **dropout**: Trong quá trình đào tạo, gán ngẫu nhiên giá trị 0 cho một vài phần tử của decoder input với xác suất p theo phân phối Bernoulli (tiếng việt: https://maths.uel.edu.vn/Resources/Docs/SubDomain/maths/TaiLieuHocTap/ToanUngDung/phn_phi_bernoulli.html, tiếng anh: https://en.wikipedia.org/wiki/Bernoulli_distribution). Mỗi channel sẽ được 0 hóa độc lập trong mỗi lần forward (lan truyền tiến). Đây đã được chứng minh là một kỹ thuật hiệu quả để chuẩn hóa (regularization) và ngăn chặn sự đồng thích ứng (co-adaptation) của các nơ-ron thần kinh như được mô tả trong bài viết https://arxiv.org/pdf/1207.0580.pdf. Hơn nữa, các đầu ra được chia tỷ lệ theo hệ số 1 / (1-p) trong quá trình đào tạo. Điều này có nghĩa là trong quá trình đánh giá, mô-đun chỉ cần tính toán một hàm identity.\n","*   **gru**: cấu trúc GRU sẽ sử dụng.\n","*   **out**: đối tượng linear transformation.\n","\n","Trong hàm khởi tạo ta sẽ truyền vào các biến sau:\n","*   **hidden_size**: kích thước (số chiều) của vector của mỗi phần tử trong tập kết quả của encoder.\n","*   **output_size**: kích thước của kết quả đầu ra.\n","*   **dropout_p**: xác suất loại bỏ.\n","*   **max_length**: số lượng từ giới hạn cho 1 câu dịch."]},{"cell_type":"code","metadata":{"id":"9nGS7Dv6GjC0","colab_type":"code","colab":{}},"source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        # A simple lookup table that stores embeddings of a fixed dictionary \n","        # and size. \n","        # This module is often used to store word embeddings and retrieve them using indices. \n","        # The input to the module is a list of indices, \n","        # and the output is the corresponding word embeddings.\n","        # output_size: num_embeddings (python:int) – size of the dictionary of embeddings\n","        # hidden_size: embedding_dim (python:int) – the size of each embedding vector\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","\n","        # Applies a linear transformation to the incoming data: y = xA^T + b\n","        # hidden_size * 2: in_features – size of each input sample\n","        # max_length: out_features – size of each output sample\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","\n","        # Applies a linear transformation to the incoming data: y = xA^T + b\n","        # hidden_size * 2: in_features – size of each input sample\n","        # hidden_size: out_features – size of each output sample\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","\n","        # During training, randomly zeroes some of the elements of \n","        # the input tensor with probability p \n","        # using samples from a Bernoulli distribution. \n","        # Each channel will be zeroed out independently on every forward call.\n","        # This has proven to be an effective technique for regularization \n","        # and preventing the co-adaptation of neurons \n","        # as described in the paper Improving neural networks by preventing co-adaptation of feature detectors .\n","        # Furthermore, the outputs are scaled by a factor of 1/(1-p) \n","        # during training. This means that during evaluation the module simply computes an identity function.\n","        # dropout_p: p – probability of an element to be zeroed. Default (when don't have parameter): 0.5\n","        # In this constructor, the default parameter (probability) is 0.1\n","        self.dropout = nn.Dropout(self.dropout_p)\n","\n","        # Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n","        # hidden_size: input_size – The number of expected features in the input x\n","        # hidden_size: hidden_size – The number of features in the hidden state h\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        \n","        # Applies a linear transformation to the incoming data: y = xA^T + b\n","        # hidden_size: in_features – size of each input sample\n","        # output_size: out_features – size of each output sample\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        # Create word embedding table based on the data -> tensor table\n","        # view(*shape): Returns a new tensor with the same data as the self tensor but of a different shape.\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        \n","        # Execute dropout process\n","        embedded = self.dropout(embedded)\n","\n","        # Execute attention process\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        # Performs a batch matrix-matrix product\n","        # unsqueeze: Returns a new tensor with a dimension of size one inserted at the specified position.\n","        #            The returned tensor shares the same underlying data with this tensor.\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        # Assuring the encoder output is not negative\n","        # Because ReLU output range is (0, +inf)\n","        output = F.relu(output)\n","\n","        # Execute GRU process\n","        output, hidden = self.gru(output, hidden)\n","\n","        # Calculate the softmax\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        # Initiate the first hidden unit\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8twwjFDuGrZF","colab_type":"text"},"source":["**Beam search**\n","\n","Thay vì ta sẽ tìm ra phân phối lớn nhất của đầu ra của decoder, ta sẽ tiến hành đi lấy top beam_width phân phối có giá trị lớn nhất. Sau đó ta sẽ tiến hành theo dõi (tracking) và chạy decoder cho từng route các giá trị này. Trong quá trình tracking, ta sẽ tiến hành tính điểm cho từng route. Kết quả ta sẽ lấy sẽ là route có số điểm tổng thể cao nhất.\n","\n","![Beam search](https://d2l.ai/_images/beam-search.svg)\n","\n","(Source: https://d2l.ai/_images/beam-search.svg)\n","\n","Đầu tiên ta sẽ đi xây dựng class dành cho mỗi node của beam search:"]},{"cell_type":"code","metadata":{"id":"MKfEWB4xJieB","colab_type":"code","colab":{}},"source":["class BeamSearchNode(object):\n","    def __init__(self, hiddenstate, previousNode, resultId, wordId, logProb, loss_value, length, decoder_attentions, decoder_output):\n","        '''\n","        :param hiddenstate:\n","        :param previousNode:\n","        :param wordId:\n","        :param logProb:\n","        :param length:\n","        '''\n","        self.h = hiddenstate\n","        self.prevNode = previousNode\n","        self.wordid = wordId\n","        self.logp = logProb\n","        self.leng = length\n","        self.id = resultId\n","        self.loss = loss_value\n","        self.da = decoder_attentions\n","        self.do = decoder_output\n","\n","    def eval(self, alpha=1.0):\n","        reward = 0\n","        # Add here a function for shaping a reward\n","\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n","\n","def check_exist(in_list, check_id):\n","    for (score, node) in in_list:\n","        if(node.id == check_id):\n","            return True\n","    return False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ToSADQ-xJszA","colab_type":"text"},"source":["Tiếp theo ta sẽ đi xây dựng hàm thực hiện quá trình beam search:"]},{"cell_type":"code","metadata":{"id":"BlnveUz0JyC5","colab_type":"code","colab":{}},"source":["def beam_search(beam_width, decoder, encoder_hidden, encoder_outputs=None, max_length=MAX_LENGTH):\n","    '''\n","    :param beam_width: beam width\n","    :param decoder: decoder object (class)\n","    :param encoder_hidden: encoder hidden after encoding process\n","    :param encoder_outputs: encoder outputs\n","    :param max_length: MAX_LENGTH limit\n","    '''\n","    # Initiate decoder input\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    # Assign encoder result to the 1st decoder hidden unit\n","    decoder_hidden = encoder_hidden\n","    \n","    # Initiate searching process\n","    queue = PriorityQueue()\n","    \n","    # starting node -  hidden vector, previous node, result id, word id, logp, loss_value, length, decoder_attentions, decoder_output\n","    node = BeamSearchNode(decoder_hidden, None, SOS_token, decoder_input, 0, 0, 1, None, None)\n","    \n","    # Put to the queue and increase its size\n","    queue.put((-node.eval(), node))\n","    qsize = 1\n","    \n","    # Initiate some variables\n","    next_node = []\n","        \n","    # Save output size\n","    target_length = max_length\n","    \n","    for di in range(target_length):\n","        # Get elements the beam\n","        while queue.empty() == False:\n","            # fetch the node from queue\n","            score, n = queue.get()\n","            qsize -= 1\n","            decoder_input = n.wordid\n","            decoder_hidden = n.h\n","            curr_id = n.id\n","            \n","            if(check_exist(next_node, curr_id) == False):\n","                # Execute decoding process\n","                decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_outputs)\n","            \n","                # Get (beam_width) top results\n","                topv, topi = decoder_output.topk(beam_width)\n","            \n","                # Create the nodes and save the results to next_nodes array\n","                for i in range(beam_width):\n","                    decoder_input = topi[0][i].squeeze().detach()\n","                    prob = n.logp + topv[0][i]\n","                    node_length = n.leng + 1\n","                    \n","                    # queue node -  hidden vector, previous node, result id, word id, logp, loss_value, length, decoder_attentions\n","                    node = BeamSearchNode(decoder_hidden, n, topi[0][i], decoder_input, prob, 0, node_length, decoder_attention.data, decoder_output)\n","                    \n","                    # Calculate the score for each node\n","                    score = -node.eval()\n","                \n","                    # Save the result\n","                    next_node.append((score, node))\n","            \n","        # Get top values (beam_width)\n","        top_values = sorted(next_node, key = lambda x: x[0], reverse = True)[:beam_width]\n","        # Put to the queue\n","        for v in top_values:\n","            queue.put(v)\n","            qsize += 1\n","        \n","        # Clear the array for the next step\n","        next_node = []\n","    \n","    utterances = []    \n","    while queue.empty() == False:\n","        # fetch the node from queue\n","        score, n = queue.get()\n","        qsize -= 1\n","            \n","        utterance = []\n","        utterance.append((n.da, n.wordid, n.do))\n","        # back trace\n","        while n.prevNode != None:\n","            n = n.prevNode\n","            utterance.append((n.da, n.wordid, n.do))\n","\n","        utterance = utterance[::-1]\n","        utterances.append(utterance)\n","            \n","    return utterances"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mpeBH3j5J9uK","colab_type":"text"},"source":["**5) Chuẩn bị quá trình huấn luyện**\n","\n","Để huấn luyện, đối với mỗi cặp, chúng ta sẽ cần một tensor (vector) đầu vào (index của các từ trong câu) và tensor đích (index của các từ trong câu đích). Trong khi tạo các vector này, ta sẽ nối thêm mã thông báo EOS vào cả hai chuỗi."]},{"cell_type":"code","metadata":{"id":"bVC4ZJ6FKAwT","colab_type":"code","colab":{}},"source":["def indexesFromSentence(lang, sentence):\n","    # Get the counter for each word in the sentence\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    # Get the counter\n","    indexes = indexesFromSentence(lang, sentence)\n","    # Append token to the end of the array\n","    indexes.append(EOS_token)\n","    # Return the vector\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    # Create input vector\n","    input_tensor = tensorFromSentence(input_lang, lemmatizer(pair[0]))\n","    # Create output vector\n","    target_tensor = tensorFromSentence(output_lang, lemmatizer(pair[1]))\n","    # Return result\n","    return (input_tensor, target_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pSRBgU6YKEXl","colab_type":"text"},"source":["**6) Quá trình huấn luyện**\n","\n","Để đào tạo, ta sẽ đưa dữ liệu đầu vào đi qua encoder, ta sẽ tiến hành theo dõi các kết quả đầu ra cũng như các giá trị trạng thái ẩn của encoder. Sau đó, ta sẽ cung cấp cho decoder token thông báo <SOS> làm tín hiệu thông báo cho decoder khởi tạo đầu vào đầu tiên, đồng thời trạng thái ẩn cuối cùng của encoder sẽ làm trạng thái ẩn đầu tiên cho decoder.\n","\n","Sau khi encoder, ta sẽ đưa vector hidden unit của encoder vào hàm chạy beam search để bắt đầu quá trình beam search decoder."]},{"cell_type":"code","metadata":{"id":"jrFfxd-3KiPQ","colab_type":"code","colab":{}},"source":["# Training function\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    \n","    # Intiatie encoder process\n","    encoder_hidden = encoder.initHidden()\n","\n","    # Clears the gradients of all optimized torch.Tensor.\n","    encoder_optimizer.zero_grad()\n","    # Clears the gradients of all optimized torch.Tensor.\n","    decoder_optimizer.zero_grad()\n","\n","    # Save input tensor size\n","    input_length = input_tensor.size(0)\n","    # Save output tensor size\n","    target_length = target_tensor.size(0)\n","\n","    # Initiate encoder output\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    # Initiate loss value\n","    loss = 0\n","\n","    # for each encoder input\n","    for ei in range(input_length):\n","        # Execute encoder process\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        # Save encoder result\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    # Initiate decoder input\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    # Initiate decoder output (beam_search)\n","    beam_width = 3\n","    # Initiate decoder attention (beam_search)\n","    bs_decoder_attentions = torch.zeros(max_length, max_length)\n","    utterances = beam_search(\n","        beam_width, decoder, encoder_hidden, encoder_outputs, target_length)\n","    bs_value = utterances[-1]\n","        \n","    for di in range(target_length):\n","        (da, word_index, do) = bs_value[di + 1]\n","        bs_decoder_attentions[di] = da\n","        # Add loss\n","        loss += criterion(do, target_tensor[di])\n","        if decoder_input.item() == EOS_token:\n","            break\n","    \n","    # Backpropagation\n","    loss.backward()\n","\n","    # Performs a single optimization step.\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cz7WVAXrK5Vr","colab_type":"text"},"source":["Ta có thể theo dõi lượng thời gian chương trình tiến hành huấn luyện bằng một số hàm sau:"]},{"cell_type":"code","metadata":{"id":"fDR9nsZRK641","colab_type":"code","colab":{}},"source":["import time\n","import math\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O9gUBIHzK9zq","colab_type":"text"},"source":["Ta viết thêm hàm vẽ biểu đồ biểu diễn sự thay đổi của giá trị loss"]},{"cell_type":"code","metadata":{"id":"pJx6OOPLK_Qi","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","%matplotlib inline\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2IUTFyVHLBGf","colab_type":"text"},"source":["Toàn bộ quá trình đào tạo trông như thế này:\n","*   Bắt đầu tính thời gian huấn luyện.\n","*   Khởi tạo bộ tối ưu hóa (optimizer) và bộ tiêu chuẩn (criterion).\n","*   Tạo một tập các cặp đào tạo (training pair).\n","*   Khởi tạo mảng loss lưu từng giá trị loss tại các thời điểm nhằm phục vụ cho việc vẽ biểu đồ.\n","\n","Cuối cùng ta sẽ gọi hàm train để thực hiện quá trình đào tạo. Kết thúc 1 lượt đào tạo ta sẽ thông báo một vài giá trị như giá trị mất mát (loss) trung bình hiện tại, thời gian huấn luyện hiện tại,..."]},{"cell_type":"code","metadata":{"id":"BIjOVGXwLCjk","colab_type":"code","colab":{}},"source":["def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    # Implements stochastic gradient descent (optionally with momentum).\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","\n","    # Randomly choose some pairs in the dataset for training process\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    # The negative log likelihood loss.\n","    # The input given through \n","    # a forward call is expected to contain log-probabilities of each class. \n","    # Input has to be a Tensor of size either (minibatch,C)\n","    # or or (minibatch, C, d1, d2, ..., dK) with K≥1 for the K-dimensional case.\n","    # Default: loss = sum((1/sum(w_(y_n))) * loss_n), loss_n = -w*x_(n,y_n)\n","    criterion = nn.NLLLoss()\n","\n","    # for each sample\n","    for iter in range(1, n_iters + 1):\n","        # Get input data and target data\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","        \n","        # Execute training process\n","        loss = train(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        # Print info\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    # Draw plot\n","    showPlot(plot_losses)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xtNO14S0LL2o","colab_type":"text"},"source":["**7) Đánh giá (evaluation)**\n","\n","Quá trình đánh giá chủ yếu cũng gần giống như đào tạo, tuy nhiên nó khác với quá trình đào tạo ở chỗ nó sẽ không đi so sánh giữa kết quả dự đoán với giá trị mong muốn (target data). Quá trình đánh giá đơn giản chỉ là ta sẽ đem các giá trị dự đoán mà decoder đã thực hiện được nạp vào lại chính nó tại mỗi bước. Mỗi lần decoder dự đoán một từ, ta sẽ thêm từ đó vào chuỗi đầu ra, khi decoder dự đoán mã thông báo (token) EOS, ta sẽ tiến hành dừng quá trình thực hiện. Chúng ta cũng nên cần lưu trữ các giá trị đầu ra của decoder attention nhằm phục vụ cho các yêu cầu hiển thị về sau."]},{"cell_type":"code","metadata":{"id":"EqW9GJ8tLLQh","colab_type":"code","colab":{}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    # Disable the gradient computation.\n","    with torch.no_grad():\n","        # Get input sample\n","        input_tensor = tensorFromSentence(input_lang, lemmatizer(sentence))\n","        input_length = input_tensor.size()[0]\n","\n","        # Initiate encoder process\n","        encoder_hidden = encoder.initHidden()\n","\n","        # Initiate encoder output\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        # for each encoder input\n","        for ei in range(input_length):\n","            # Execute encoder process\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            # Save encoder result\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        # Initiate decoder input\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        # Assign encoder result to the 1st decoder hidden unit\n","        decoder_hidden = encoder_hidden\n","\n","        # Initiate decoder output (greedy_search)\n","        decoded_words = []\n","        # Initiate decoder attention (greedy_search)\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","        \n","        # for each decoder input (greedy_search)\n","        for di in range(max_length):\n","            # Execute decoder process\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            # Save decoder attention\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","        \n","        # Initiate decoder output (beam_search)\n","        beam_width = 3\n","        bs_decoded_words = []\n","        # Initiate decoder attention (beam_search)\n","        bs_decoder_attentions = torch.zeros(max_length, max_length)\n","        utterances = beam_search(\n","            beam_width, decoder, encoder_hidden, encoder_outputs, MAX_LENGTH)\n","        bs_value = utterances[-1]\n","        \n","        for di in range(max_length):\n","            (da, word_index) = bs_value[di + 1]\n","            bs_decoder_attentions[di] = da\n","            if word_index.item() == EOS_token:\n","                bs_decoded_words.append('<EOS>')\n","                break\n","            else:\n","                bs_decoded_words.append(output_lang.index2word[word_index.item()])\n","        \n","        return decoded_words, decoder_attentions[:di + 1], bs_decoded_words, bs_decoder_attentions[:di + 1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DWoBgT5yLbLn","colab_type":"text"},"source":["Ta có thể thực hiện đánh giá bằng việc chọn ngẫu nhiên một số dữ liệu từ tập dữ liệu:"]},{"cell_type":"code","metadata":{"id":"4AGcB9Z6Lcxu","colab_type":"code","colab":{}},"source":["def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        print(\"-----------------------------------------------------------\")\n","        pair = random.choice(pairs)\n","        print('Input:', pair[0])\n","        print('Goal:', pair[1])\n","        output_words, attentions, bs_output, bs_attentions = evaluate(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        bs_sentence = ' '.join(bs_output)\n","        print('Greedy search:', output_sentence)\n","        print('Beam search:', bs_sentence)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sZUslBMQLe2y","colab_type":"text"},"source":["**8) Thực hiện huấn luyện và đánh giá**\n","\n","Đầu tiên ta sẽ cho chương trình thực hiện việc huấn luyện mô hình."]},{"cell_type":"code","metadata":{"id":"U9wofL6qLf_j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"f25bae9b-59d3-4b59-f934-52346d6e4121"},"source":["hidden_size = 250\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["7m 31s (- 105m 22s) (5000 6%) 4.6992\n","14m 56s (- 97m 9s) (10000 13%) 4.1842\n","22m 26s (- 89m 45s) (15000 20%) 3.9397\n","29m 55s (- 82m 17s) (20000 26%) 3.7861\n","37m 28s (- 74m 57s) (25000 33%) 3.6538\n","45m 0s (- 67m 30s) (30000 40%) 3.5304\n","52m 19s (- 59m 47s) (35000 46%) 3.4294\n","59m 42s (- 52m 14s) (40000 53%) 3.3322\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6zqQqpYILk2Y","colab_type":"text"},"source":["Sau đó ta sẽ tiến hành thực hiện đánh giá."]},{"cell_type":"code","metadata":{"id":"0ll99f9ILwQd","colab_type":"code","colab":{}},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bH_OeaViLykx","colab_type":"text"},"source":["**9) Hiển thị hóa attention**\n","\n","Một đặc tính hữu ích của cơ chế attention đó là các đầu ra của nó rất dễ hiểu. Bởi vì nó được sử dụng để xử lý các giá trị đầu ra của encoder từ các chuỗi dữ liệu đầu vào, nhờ vào attention ta có thể biết hệ thống mạng đang tập trung ở đâu tại mỗi bước thời gian."]},{"cell_type":"code","metadata":{"id":"5CngMAYAL1em","colab_type":"code","colab":{}},"source":["def showAttention(input_sentence, output_words, attentions):\n","    # Set up figure with colorbar\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(attentions.numpy(), cmap='bone')\n","    fig.colorbar(cax)\n","\n","    # Set up axes\n","    ax.set_xticklabels([''] + input_sentence.split(' ') +\n","                       ['<EOS>'], rotation=90)\n","    ax.set_yticklabels([''] + output_words)\n","\n","    # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","\n","\n","def evaluateAndShowAttention(input_sentence):\n","    output_words, attentions, bs_output, bs_attentions = evaluate(\n","        encoder1, attn_decoder1, input_sentence)\n","    print('input =', input_sentence)\n","    print('greedy search =', ' '.join(output_words))\n","    print('beam search =', ' '.join(bs_output))\n","    print('Greedy_search attention:')\n","    showAttention(input_sentence, output_words, attentions)\n","    print('Beam_search attention:')\n","    showAttention(input_sentence, bs_output, bs_attentions)\n","    \n","\n","evaluateAndShowAttention(normalizeString(\"i know all the possibility .\".lower().strip()))\n","\n","evaluateAndShowAttention(normalizeString(\"they kill me .\".lower().strip()))\n","\n","evaluateAndShowAttention(normalizeString(\"let me tell you a story .\".lower().strip()))"],"execution_count":0,"outputs":[]}]}